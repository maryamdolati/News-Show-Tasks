# -*- coding: utf-8 -*-
"""task 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PbIRe98Jo3rX4MIq3RDsuRzQ3ROKOxqM
"""

import pandas as pd

# Mount your Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""**To do task 2, I used the data of task one for testing and the data of task two for training as you said.**"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
import json
import pandas as pd

# Read the CSV file
csv_path = '/content/drive/MyDrive/to_fill.csv'
df = pd.read_csv(csv_path)

# Define a function to extract the body, start time, and end time from a JSON file
def extract_info(json_path):
    with open(json_path, 'r') as f:
        json_data = json.load(f)
    
    body = json_data['text']  # replace 'full_text' with 'text'
    start = json_data['words'][0]['start']
    end = json_data['words'][-1]['end']
    
    return body, start, end


# Define a function to extract the first 8 and last 8 words from a story
def extract_first_last_words(row):
    words = row['body'].split()
    first_words = ' '.join(words[:8])
    last_words = ' '.join(words[-8:])
    return first_words, last_words



# Iterate over the JSON file paths and add the required columns to the dataframe
json_paths = ['/content/drive/MyDrive/18246.json',
              '/content/drive/MyDrive/16859.json',
              '/content/drive/MyDrive/12387.json']

for json_path in json_paths:
    transcription_id = json_path.split('/')[-1].split('.')[0]
    body, start, end = extract_info(json_path)
    df.loc[df['source_video_id'] == int(transcription_id), 'body'] = body
    df.loc[df['source_video_id'] == int(transcription_id), 'start'] = start
    df.loc[df['source_video_id'] == int(transcription_id), 'end'] = end

# Apply the function to create new columns for first and last words
df['first_words'], df['last_words'] = zip(*df.apply(extract_first_last_words, axis=1))

# Display the resulting dataframe
print(df.head())

# Load the data
train_df = pd.read_csv('/content/drive/MyDrive/stories.csv')

# Preprocess the text data
vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(train_df['body'])
y_train = train_df['topic']
X_test = vectorizer.transform(df['body'])


# Train a Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_train, y_train)

# Predict topics for new data
new_X = vectorizer.transform(df['body'])
new_y_pred = clf.predict(new_X)

# Add predicted topics to the dataframe
df = df.assign(topics=new_y_pred)

# Print the first 10 rows of the updated dataframe
print(df.head(10))