{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFsc9g8oO1Oh",
        "outputId": "07537583-ed81-4663-c792-b85ca939147c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To do task 2, I used the data of task one for testing and the data of task two for training as you said.**"
      ],
      "metadata": {
        "id": "RGddeJ2KM9kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "csv_path = '/content/drive/MyDrive/to_fill.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Define a function to extract the body, start time, and end time from a JSON file\n",
        "def extract_info(json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "    \n",
        "    body = json_data['text']  # replace 'full_text' with 'text'\n",
        "    start = json_data['words'][0]['start']\n",
        "    end = json_data['words'][-1]['end']\n",
        "    \n",
        "    return body, start, end\n",
        "\n",
        "\n",
        "# Define a function to extract the first 8 and last 8 words from a story\n",
        "def extract_first_last_words(row):\n",
        "    words = row['body'].split()\n",
        "    first_words = ' '.join(words[:8])\n",
        "    last_words = ' '.join(words[-8:])\n",
        "    return first_words, last_words\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over the JSON file paths and add the required columns to the dataframe\n",
        "json_paths = ['/content/drive/MyDrive/18246.json',\n",
        "              '/content/drive/MyDrive/16859.json',\n",
        "              '/content/drive/MyDrive/12387.json']\n",
        "\n",
        "for json_path in json_paths:\n",
        "    transcription_id = json_path.split('/')[-1].split('.')[0]\n",
        "    body, start, end = extract_info(json_path)\n",
        "    df.loc[df['source_video_id'] == int(transcription_id), 'body'] = body\n",
        "    df.loc[df['source_video_id'] == int(transcription_id), 'start'] = start\n",
        "    df.loc[df['source_video_id'] == int(transcription_id), 'end'] = end\n",
        "\n",
        "# Apply the function to create new columns for first and last words\n",
        "df['first_words'], df['last_words'] = zip(*df.apply(extract_first_last_words, axis=1))\n",
        "\n",
        "# Display the resulting dataframe\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9to1JfHQkTA",
        "outputId": "f2e5fc8f-900c-4dcd-e6fd-64a9f80f5d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         first_words  \\\n",
            "0              And that's just what Guy Al has done.   \n",
            "1  Bit unusual. Ktv crime reporter Henry Lee joining   \n",
            "2       Yesterday. We're on 115 for those hot spots,   \n",
            "3              And that's just what Guy Al has done.   \n",
            "4       Yesterday. We're on 115 for those hot spots,   \n",
            "\n",
            "                                        last_words  source_video_id  \\\n",
            "0  the country. Mandela's visit comes as the most.            18246   \n",
            "1        win. It's time to make this thing happen.            12387   \n",
            "2   With your good credit, celebrate the start of.            16859   \n",
            "3  the country. Mandela's visit comes as the most.            18246   \n",
            "4   With your good credit, celebrate the start of.            16859   \n",
            "\n",
            "                                                body  start        end  \n",
            "0  And that's just what Guy Al has done. She take...   70.0   717620.0  \n",
            "1  Bit unusual. Ktv crime reporter Henry Lee join...  190.0   717560.0  \n",
            "2  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0  \n",
            "3  And that's just what Guy Al has done. She take...   70.0   717620.0  \n",
            "4  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/stories.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['body'])\n",
        "y_train = train_df['topic']\n",
        "X_test = vectorizer.transform(df['body'])\n",
        "\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict topics for new data\n",
        "new_X = vectorizer.transform(df['body'])\n",
        "new_y_pred = clf.predict(new_X)\n",
        "\n",
        "# Add predicted topics to the dataframe\n",
        "df = df.assign(topics=new_y_pred)\n",
        "\n",
        "# Print the first 10 rows of the updated dataframe\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuPPFrZiFhvy",
        "outputId": "52d1b1be-7cb3-4339-bc14-cc6c02b3b46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         first_words  \\\n",
            "0              And that's just what Guy Al has done.   \n",
            "1  Bit unusual. Ktv crime reporter Henry Lee joining   \n",
            "2       Yesterday. We're on 115 for those hot spots,   \n",
            "3              And that's just what Guy Al has done.   \n",
            "4       Yesterday. We're on 115 for those hot spots,   \n",
            "5              And that's just what Guy Al has done.   \n",
            "6              And that's just what Guy Al has done.   \n",
            "7  Bit unusual. Ktv crime reporter Henry Lee joining   \n",
            "8       Yesterday. We're on 115 for those hot spots,   \n",
            "9       Yesterday. We're on 115 for those hot spots,   \n",
            "\n",
            "                                        last_words  source_video_id  \\\n",
            "0  the country. Mandela's visit comes as the most.            18246   \n",
            "1        win. It's time to make this thing happen.            12387   \n",
            "2   With your good credit, celebrate the start of.            16859   \n",
            "3  the country. Mandela's visit comes as the most.            18246   \n",
            "4   With your good credit, celebrate the start of.            16859   \n",
            "5  the country. Mandela's visit comes as the most.            18246   \n",
            "6  the country. Mandela's visit comes as the most.            18246   \n",
            "7        win. It's time to make this thing happen.            12387   \n",
            "8   With your good credit, celebrate the start of.            16859   \n",
            "9   With your good credit, celebrate the start of.            16859   \n",
            "\n",
            "                                                body  start        end  \\\n",
            "0  And that's just what Guy Al has done. She take...   70.0   717620.0   \n",
            "1  Bit unusual. Ktv crime reporter Henry Lee join...  190.0   717560.0   \n",
            "2  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0   \n",
            "3  And that's just what Guy Al has done. She take...   70.0   717620.0   \n",
            "4  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0   \n",
            "5  And that's just what Guy Al has done. She take...   70.0   717620.0   \n",
            "6  And that's just what Guy Al has done. She take...   70.0   717620.0   \n",
            "7  Bit unusual. Ktv crime reporter Henry Lee join...  190.0   717560.0   \n",
            "8  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0   \n",
            "9  Yesterday. We're on 115 for those hot spots, s...  790.0  1316540.0   \n",
            "\n",
            "                                     topics  \n",
            "0  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "1  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "2  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "3  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "4  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "5  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "6  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "7  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "8  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n",
            "9  ['9ff54ded-904b-4e0c-85ce-a3617f5cb913']  \n"
          ]
        }
      ]
    }
  ]
}